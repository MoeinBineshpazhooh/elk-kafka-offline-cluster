input {
  kafka {
    bootstrap_servers => "${KAFKA_BOOTSTRAP_SERVERS}"
    topics => ${KAFKA_TOPICS}
    group_id => "${KAFKA_GROUP_ID:logstash-consumers}"
    client_id => "${KAFKA_CLIENT_ID:logstash}"
    auto_offset_reset => "${KAFKA_AUTO_OFFSET_RESET:latest}"
    decorate_events => true
    consumer_threads => ${KAFKA_CONSUMER_THREADS:2}
    codec => json
  }
}

filter {
  # Optional: add basic metadata fields
  mutate {
    add_field => {
      "[@metadata][source]" => "kafka"
    }
  }
}

output {
  elasticsearch {
    hosts => [ "${ELASTICSEARCH_HOSTS}" ]
    user => "${ELASTICSEARCH_USERNAME}"
    password => "${ELASTICSEARCH_PASSWORD}"

    # TLS trust (CA)
    ssl_certificate_authorities => "${ELASTICSEARCH_SSL_CACERT}"
    ssl_verification_mode => "${ELASTICSEARCH_SSL_VERIFICATIONMODE:full}"

    # Index naming (simple daily index)
    index => "kafka-logs-%{+YYYY.MM.dd}"
  }

  # Debug (optional)
  # stdout { codec => rubydebug }
}
